DAY10
* colab 알아보기
* 노트북 알아보기
* 데이터 과학 120page 코딩 과제
* 복습
* github 정리
* 주말 없음


05월 22일 수업

과제는 꼭 제출하자!
보냈는데 지메일 수신확인에서 아직 선생님이 확인 안했다고 나오는데..
수업 마치고 물어봐야겠다.

time limit 지키자.

가장 base 책 : 데이터 과학

무조건 앞에서부터 읽는다고 생각 no
필요한 부분 찾으면서 중간중간 모두 보기
중복 부분 많음 책 5권
한 권 읽으면 다른 책 읽기 수월, 껌이다...ㅋㅋ

주말에 복습, 깃허브 정리, 책까지 읽어야한다.....하하하하핳ㅎㅎㅎㅎㅎㅎㅎ
오늘은 자습때까지만 공부하고 좀 쉬어도 되겠지
토, 일 빡시게..굴려야 할 듯

내일 저녁 쉬는 시간에 염색하고!
오늘 반, 자리 배치하는 날
제비뽑기....과연..


어디서 끝나는가

keras34_lstrm_earlystopping.py
기존의 32lstm hamsu 파일 복붙, early_stopping 적용

226
453
325
435
218 - 81.13399
390 - 80.92485
552 - 80.948654
452 - 80.90706
214 - 79.42005


리턴 시퀀스 : 차원이 이어진다(유지된다)!!!!!가장 중요

summary에서 output node의 갯수는 feature의 갯수와 같다



13, 3, 1 featur의 갯수와 input_dim 의 수는 같다
첫 번째 레이어 none, 3, 1 (첫 번째 input layer의 차원) (13,3,1)이지만 행은 무시하기 때문에 none
두 번째 레이어 

(lstm 뿐만 아니라)output node의 갯수는 다음 layer의 feature의 갯수와 같다

LSTM parameter 게산은
(input_dim + bias + output) * 4(gate4) * output_node

bias는 레이어 하나당 하나!
따라서 항상 연산 할 때 bias는 1이다
레이어 하나에 항상 존재하는 전지전능한 bias!!!










