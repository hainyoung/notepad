-------------------------self study

* 딥러닝 기초 : 파이썬 넘파이(numpy)기본 사용법
어떤 딥러닝 책을 보더라도 배열이나 행렬 계산이 많이 등장한다.
numpy의 배열 class인 numpy.arrray에는 편리한 함수가 많이 준비되어 있어서 
D.L을 구현할 때 많이 이용

1. numpy 가져오기
numpy는 외부 library이기 때문에 numpy를 사용할 수 있게 import 해야 한다.
여기서 as np는 numpy의 별칭을 np로 두겠다는 의미.
즉, numpy를 하지 않고 numpy가 제공하는 함수를 np를 통해 참조할 수 있게 된다.

2. 배열 생성하기
numpy 배열을 만들 때는 np.array() method(메서드)를 이용.
이 함수는 python의 list를 인수로 받아서 numpy가 제공하는 특수한 형태의 배열을 반환
(쉽게, 기계에게 인식하기 쉽게, 좋게 만들어준다고 생각해도 됨)

3. 산술 연산
numpy 배열로 산술 연산을 할 수 있음

import numpy as np
 
x= np.array([1, 2, 3, 4, 5])
y = np.array([6, 7, 8, 9 ,10])

print(x)
print(y)

print(x+y)
print(x*y)
print(x-y)

[1 2 3 4 5]
[6 7 8 9 10]

[7 9 11 13 15]
[6 14 24 36 50]
[-5 -5 -5 -5 -5]

4. 위의 예시는 1차원 배열인데 numpy에서는 다차원 배열도 작성할 수 있음

import numpy as np

x = np.array([1, 2, 3, 4, 5], [6, 7, 8, 9, 10])
y = np.array([2, 2, 2, 2, ,2], [4, 4, 4, 4, 4])

print(x.shape)

[[1 2 3 4 5]
[6 7 8 9 10]]
[[2 2 2 2 2]
[4 4 4 4 4]]

(2, 5)

shape 함수는 각 배열의 차원의 크기(2, 5 즉, 2행 5열을 반환해준다.
(print(x), print(y)는 생략)

- 수학에서 1차원 배열은 벡터(Vector), 2차원 배열은 행렬(Matrix)라고 함.
- 그리고 Vector와 행렬을 일반화한 것을 텐서(Tensor)라고 함.



---------------------------오전수업


# overfitting 과적합
과제 : R2를 0.5 이하 값 만들기(음수는 x)

solution: node or layer or epochs를 겁나게 올림
사람은 너무 많이 쳐먹으면 토함
machine도 마찬가지

ex) 
acc or R2 - epochs 상관관계의 그래프에서
epochs 증가 할 때 acc(R2)도 따라서 증가하지만 어느 지점에서부터는
그래프의 선이 요동을 침
why? 
너무 과도한 훈련 때문.
이를 과적합이라 함
acc(R2) 의 수치가 요동치기 전까지의 그 point가 최적점
여기서 끊어야 좋은 model이 만들어짐
-> early stopping 이라고 함.
(Early stopping 은 무조건 Epoch 을 많이 돌린 후, 특정 시점에서 멈추는 것)

loss의 경우는 어떨까? (mse, rmse)
acc, R2의 그래프와는 반대로 epochs가 증가함에 따라 점점 낮아지다가
어느 지점부터 그래프는 요동 침
이 때, 이 지점은 acc(or R2)가 요동치는 지점과 같을 것이며
이 역시 마찬가지 early stopping 해야 함

---------------------------------------오후수업

* 지금까지 data 우리가 직접 자름 (손으로)
발로도 할 수 있음? ㅋㅋ
	x	y
train
val
test

data 분류, 조금 더 쉽고 잘 좋게 만들어주는 무언가가 있을 것
함수로 구현 가능? yes i can...
but 직접 함수 만들지 않고 이미 있는 것을 통해 data 자를 수 있음
data set을 train, test로 편하게 분리해주는 api 함수? 클래스? 
하여튼 걔를 가져와 써 보자
이미 만들어져있다
어디에? 구글? nope.
딥러닝 전에 머신러닝이 있었음
머신러닝에서 이미 데이터 자르는 것 존재.
어제 불러 보았던 사이킷런에 잘 잘라주는 그것이 존재함. 

지금까지 한 작업 가내수공업 같음
명색이 인공지능인데..
사실 필드 나가면 가내수공업 많이 해야함

지금부터는 다른 것을 이용해서 data를 분류해보자.


----------------keras12_split.py
from.sklearn.model_selection import train_test_split    
	
x_train, x_test, y_train, y_test = train_test_split(   
	
    x, y, random_state=66, test_size=0.2                
)


# train_test_split을 하는데 model selection 안에 있음 (이미 구현된 함수)
# train_test_split() = ()안에 것을 받아들임. x, y의 통data를 받겠다. 
# random_state = ?(나중에), test_size = train size가...수업 끊김

prarameter = 매개변수 비슷하다고 생각하면 됨

training 80
val 20

train에서 다시 train, val 나눠줘야 함

아니면 아예 train 6, test4로 하고
test에서 val 2, test2로 나눠도 됨.

결과는 같음
training에서 무조건 train, val로 나누지 않아도 됨
태어날 때부터 test인 데이터는 없음
통, 전체 data에서 우리가 임의로 train, val, test 나눠주는 것임

shuffule 섞는 것
카드놀이 할 때 셔플
랜덤으로 섞겠다는 뜻

shuffle=True (섞겠다. 이게 default옵션, 입력하지 않아도 shuffle true로 판단)
random_state=66
원래 shuffle은 할 때마다 바뀜
random : 난수

1,2,3,4,5

random 난수 1이라 하면 13524 순서로 나옴
random 1, random2, random3, ....... 모두 순서가 있음

즉, random_state=66 이라고 하면
몇 번을 돌리든 나오는 순서는 11, 87, 12, ... 동일하게 나옴.

직접 해 보자.
[11 87 12 38 62  2 29 37 72 47 70 23 18 56 54 31  8 68 64 90 20 96 63 79
 66 43 99 65 36 35 77 58 45 10 41 57 13 60 82  7  3 33 92 32 48 76 28 14
 40 17 97 75 98 22 91 80 78 52 61 21]
[ 5 95 39  9 73 85  1 19 34 25 44 74 81 93 26 86 15 51 30 50]
[ 53  59 100  42  94  84   6  24  49  55  71   4  16  46  69  67  89  27
  88  83]

[11 87 12 38 62  2 29 37 72 47 70 23 18 56 54 31  8 68 64 90 20 96 63 79
 66 43 99 65 36 35 77 58 45 10 41 57 13 60 82  7  3 33 92 32 48 76 28 14
 40 17 97 75 98 22 91 80 78 52 61 21]
[ 5 95 39  9 73 85  1 19 34 25 44 74 81 93 26 86 15 51 30 50]
[ 53  59 100  42  94  84   6  24  49  55  71   4  16  46  69  67  89  27
  88  83]
-------------두 번 실행, 동일하게 나옴

random_state=66을 지우면
[ 94  30  71  33  45  83  13  88  97  79  17  12  40   2  98  72  36  41
  99  38  93  32  55  46  14  29  20  66  48  81  52  51   5  11  35  44
  63  67  23 100  75   1  31  87  64  26  62   4   8  43  68  16  57  96
   3  21  82  84  89  70]
[10  9 69 65 50 24 56 85 47 34 54 39 78 58 19 42 18 61 53 27]
[ 7 74 60 25 28 15 91 77 49 37 76 80 90  6 59 73 86 95 22 92]

[ 56  74  80  43  33  58  97  88  13  98  50   4   6  17  79  78  75  38
   1  87  42  35  31  91  54  77 100   9  10  22  26  68  23   5  11  55
  25   7  48  52  95  84  76  32  86  89  64  18  12  71  85   8  39  83
  16  66  70  36  21  27]
[67 45 44 30 51 41 15 60 62 29 94  3 96 53 65 40 73  2 61 81]
[46 93 90 28 24 69 14 20 47 49 57 72 19 59 63 92 34 37 99 82]
 
-------------두 번 실행, 다르게 나옴.

shuffle을 하는 이유

초반에 했던 방식
1부터 80 train
80부너 100 test
주어지는 구간 밖의 값을 잘 못 구함.
shuffle을 하면 다양한 범위 내 무작위로 훈련을 시켜서
정확도 더 높아진다
범위 밖의 값을 더 잘 맞춤

그냥 순서 상관 없이 60개 40개 
x, y 쌍으로 넣음 

ex)
w값이 2일 때

x 1 2 3 4 5
y 2 4 6 8 10 라는 데이터가 주어졌다면,

train 3 1 5 | test 4 2
test 6 2 10 | test 8 4
(x값과 y값은 같이 섞임)

정확도 더 높아진다
범위 밖의 값을 더 잘 맞춤


서울의 기온
영하 20, 영상 35
매일 

백견이 불여일타!!!!!!!!!!!!!!

validation을 훈련과정에서 퍼센티지를 준다.
model fit 안에 
train과 val 구분하지 않고
train-split 한 번만 하면 되고
train 과 val을 구분할 수 잇는 파라미터를 찾아봐라
- validation_split


train_size 0.6
test_size 0.5
같이 넣어서 실행시켜보기

train_size 0.6
test_size0.3












